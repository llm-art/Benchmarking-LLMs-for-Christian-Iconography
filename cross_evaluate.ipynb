{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common code block with reused functions and imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define test paths\n",
    "test_1_path = 'test_1'\n",
    "test_2_path = 'test_2'\n",
    "test_3_path = 'test_3'\n",
    "\n",
    "def get_accuracy(folder_path, dataset_name):\n",
    "    \"\"\"Get accuracy values for all models in a dataset folder\"\"\"\n",
    "    folder_path = os.path.join(folder_path, dataset_name)\n",
    "    accuracy_dict = {}\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        return accuracy_dict\n",
    "        \n",
    "    for model_folder in os.listdir(folder_path):\n",
    "        model_path = os.path.join(folder_path, model_folder)\n",
    "        if os.path.isdir(model_path):\n",
    "            summary_file = os.path.join(model_path, 'summary_metrics.csv')\n",
    "            if os.path.exists(summary_file):\n",
    "                df = pd.read_csv(summary_file)\n",
    "                accuracy = df.loc[df['Model'] == model_folder, 'Accuracy'].values[0]\n",
    "                accuracy_dict[model_folder] = accuracy\n",
    "    return accuracy_dict\n",
    "\n",
    "def create_dataframe(dataset_name, test_1_accuracy, test_2_accuracy, test_3_accuracy):\n",
    "    \"\"\"Create a DataFrame with accuracy values for all tests\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'Model': list(test_1_accuracy.keys()),\n",
    "        'Test 1': list(test_1_accuracy.values()),\n",
    "        'Test 1 (few-shot)': [test_3_accuracy.get(model, '') for model in test_1_accuracy.keys()],\n",
    "        'Test 2': [test_2_accuracy.get(model, '') for model in test_1_accuracy.keys()],\n",
    "    })\n",
    "    \n",
    "    # Set index and sort\n",
    "    df.set_index('Model', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    # Reorder specific models if they exist\n",
    "    for model in ['gpt-4o-mini', 'gpt-4o', 'clip-vit-base-patch32']:\n",
    "        if model in df.index:\n",
    "            df = df.reindex([idx for idx in df.index if idx != model] + [model])\n",
    "    \n",
    "    # Move clip-vit-base-patch32 to the top if it exists\n",
    "    if 'clip-vit-base-patch32' in df.index:\n",
    "        df = df.reindex(['clip-vit-base-patch32'] + [idx for idx in df.index if idx != 'clip-vit-base-patch32'])\n",
    "    \n",
    "    # Rename columns based on dataset\n",
    "    df.columns = ['zero-shot (labels)', f'few-shot[*](dataset/{dataset_name}-data/few-shot/README.md) (labels)', 'zero-shot (descriptions)']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_baseline(dataset_name):\n",
    "    \"\"\"Calculate baseline accuracy from baseline.csv if it exists\"\"\"\n",
    "    baseline_path = f'dataset/{dataset_name}-data/baseline.csv'\n",
    "    if os.path.exists(baseline_path):\n",
    "        baseline_df = pd.read_csv(baseline_path)\n",
    "        baseline_df = baseline_df[baseline_df['Class Name'] != 'Mean']\n",
    "        \n",
    "        # Calculate TP as recall * (TP + FN) = recall * # Test Images\n",
    "        baseline_df['Recall'] = baseline_df['Recall'].str.rstrip('%').astype('float') / 100.0\n",
    "        baseline_df['# Test Images'] = baseline_df['# Test Images'].str.replace(',', '').astype('int')\n",
    "        baseline_df['True Positives'] = baseline_df['# Test Images'] * baseline_df['Recall']\n",
    "        \n",
    "        # Calculate accuracy as TP / # Test Images\n",
    "        total_true_positives = baseline_df['True Positives'].sum()\n",
    "        total_test_images = baseline_df['# Test Images'].sum()\n",
    "        baseline_accuracy = total_true_positives / total_test_images\n",
    "        \n",
    "        return baseline_accuracy\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ArtDL Results\n",
      "| Model                     | zero-shot (labels)   | few-shot[*](dataset/ArtDL-data/few-shot/README.md) (labels)   | zero-shot (descriptions)   |\n",
      "|:--------------------------|:---------------------|:--------------------------------------------------------------|:---------------------------|\n",
      "| clip-vit-base-patch32     | 16.15%               | 21.41%                                                        | 31.55%                     |\n",
      "| clip-vit-base-patch16     | 25.64%               | 29.13%                                                        | 28.70%                     |\n",
      "| clip-vit-large-patch14    | 30.58%               | 31.71%                                                        | 44.31%                     |\n",
      "| siglip-base-patch16-512   | 48.71%               | 55.90%                                                        | 68.19%                     |\n",
      "| siglip-large-patch16-384  | 54.45%               | 53.49%                                                        | 72.21%                     |\n",
      "| siglip-so400m-patch14-384 | 53.86%               | 56.38%                                                        | 70.55%                     |\n",
      "| gpt-4o-mini               | 69.96%               | 82.46%                                                        | 63.68%                     |\n",
      "| gpt-4o                    | 85.03%               | 85.03%                                                        | 89.06%                     |\n",
      "| Baseline                  | 84.44%               |                                                               |                            |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset: ArtDL\n",
    "dataset_name = \"ArtDL\"\n",
    "test_1_accuracy = get_accuracy(test_1_path, dataset_name)\n",
    "test_2_accuracy = get_accuracy(test_2_path, dataset_name)\n",
    "test_3_accuracy = get_accuracy(test_3_path, dataset_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = create_dataframe(dataset_name, test_1_accuracy, test_2_accuracy, test_3_accuracy)\n",
    "\n",
    "# Add baseline if available\n",
    "baseline_accuracy = calculate_baseline(dataset_name)\n",
    "if baseline_accuracy is not None:\n",
    "    df.loc['Baseline'] = [f\"{baseline_accuracy:.2%}\", \"\", \"\"]\n",
    "\n",
    "# Format and display\n",
    "print(f\"## {dataset_name} Results\")\n",
    "print(df.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ICONCLASS Results\n",
      "| Model                     | zero-shot (labels)   | few-shot[*](dataset/ICONCLASS-data/few-shot/README.md) (labels)   | zero-shot (descriptions)   |\n",
      "|:--------------------------|:---------------------|:------------------------------------------------------------------|:---------------------------|\n",
      "| clip-vit-base-patch32     | 23.48%               | 29.56%                                                            | 26.35%                     |\n",
      "| clip-vit-base-patch16     | 28.89%               | 32.60%                                                            | 26.35%                     |\n",
      "| clip-vit-large-patch14    | 39.36%               | 42.74%                                                            | 34.29%                     |\n",
      "| siglip-base-patch16-512   | 43.41%               | 42.23%                                                            | 31.59%                     |\n",
      "| siglip-large-patch16-384  | 49.16%               | 49.49%                                                            | 36.82%                     |\n",
      "| siglip-so400m-patch14-384 | 57.77%               | 59.46%                                                            | 51.69%                     |\n",
      "| gpt-4o-mini               | 50.17%               | 49.16%                                                            | 52.20%                     |\n",
      "| gpt-4o                    | 54.86%               | 65.88%                                                            | 34.07%                     |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset: ICONCLASS\n",
    "dataset_name = \"ICONCLASS\"\n",
    "test_1_accuracy = get_accuracy(test_1_path, dataset_name)\n",
    "test_2_accuracy = get_accuracy(test_2_path, dataset_name)\n",
    "test_3_accuracy = get_accuracy(test_3_path, dataset_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = create_dataframe(dataset_name, test_1_accuracy, test_2_accuracy, test_3_accuracy)\n",
    "\n",
    "# Format and display\n",
    "print(f\"## {dataset_name} Results\")\n",
    "print(df.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## wikidata Results\n",
      "| Model                     | zero-shot (labels)   | few-shot[*](dataset/wikidata-data/few-shot/README.md) (labels)   | zero-shot (descriptions)   |\n",
      "|:--------------------------|:---------------------|:-----------------------------------------------------------------|:---------------------------|\n",
      "| clip-vit-base-patch32     | 40.95%               |                                                                  | 42.20%                     |\n",
      "| clip-vit-base-patch16     | 48.33%               |                                                                  | 42.90%                     |\n",
      "| clip-vit-large-patch14    | 54.46%               |                                                                  | 50.84%                     |\n",
      "| siglip-base-patch16-512   | 56.55%               |                                                                  | 45.40%                     |\n",
      "| siglip-large-patch16-384  | 60.31%               |                                                                  | 40.39%                     |\n",
      "| siglip-so400m-patch14-384 | 65.32%               |                                                                  | 59.89%                     |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset: IconArt\n",
    "dataset_name = \"wikidata\"\n",
    "test_1_accuracy = get_accuracy(test_1_path, dataset_name)\n",
    "test_2_accuracy = get_accuracy(test_2_path, dataset_name)\n",
    "test_3_accuracy = get_accuracy(test_3_path, dataset_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = create_dataframe(dataset_name, test_1_accuracy, test_2_accuracy, test_3_accuracy)\n",
    "\n",
    "# Format and display\n",
    "print(f\"## {dataset_name} Results\")\n",
    "print(df.to_markdown())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Dataset: [NEW_DATASET_NAME]\\ndataset_name = \"[NEW_DATASET_NAME]\"\\ntest_1_accuracy = get_accuracy(test_1_path, dataset_name)\\ntest_2_accuracy = get_accuracy(test_2_path, dataset_name)\\ntest_3_accuracy = get_accuracy(test_3_path, dataset_name)\\n\\n# Create DataFrame\\ndf = create_dataframe(dataset_name, test_1_accuracy, test_2_accuracy, test_3_accuracy)\\n\\n# Add baseline if available\\nbaseline_accuracy = calculate_baseline(dataset_name)\\nif baseline_accuracy is not None:\\n    df.loc[\\'Baseline\\'] = [f\"{baseline_accuracy:.2%}\", \"\", \"\"]\\n\\n# Format and display\\nprint(f\"## {dataset_name} Results\")\\nprint(df.to_markdown())\\nprint(\"\\n\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template for adding a new dataset\n",
    "\"\"\"\n",
    "# Dataset: [NEW_DATASET_NAME]\n",
    "dataset_name = \"[NEW_DATASET_NAME]\"\n",
    "test_1_accuracy = get_accuracy(test_1_path, dataset_name)\n",
    "test_2_accuracy = get_accuracy(test_2_path, dataset_name)\n",
    "test_3_accuracy = get_accuracy(test_3_path, dataset_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = create_dataframe(dataset_name, test_1_accuracy, test_2_accuracy, test_3_accuracy)\n",
    "\n",
    "# Add baseline if available\n",
    "baseline_accuracy = calculate_baseline(dataset_name)\n",
    "if baseline_accuracy is not None:\n",
    "    df.loc['Baseline'] = [f\"{baseline_accuracy:.2%}\", \"\", \"\"]\n",
    "\n",
    "# Format and display\n",
    "print(f\"## {dataset_name} Results\")\n",
    "print(df.to_markdown())\n",
    "print(\"\\n\")\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
